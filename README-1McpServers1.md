# MCP Servers

## Install environments

MCP User's Guide => Quickstart => For Server Developers
https://modelcontextprotocol.io/quickstart/server

### Node.js Weather MCP Server
```
git clone https://github.com/modelcontextprotocol/quickstart-resources.git
cd quickstart-resources
cd weather-server-typescript
npm install
npm run build
node build/index.js
    Weather MCP Server running on stdio

node d:\development\mcp-servers\quickstart-resources\weather-server-typescript\build\index.js
    Weather MCP Server running on stdio

cd ..
```

### Python Weather MCP Server
```cmd
cd weather-server-python
uv sync
uv run weather.py
    Weather MCP Server running on stdio

cd c:\Users\samfi
weather.bat
    Weather MCP Server running on stdio

REM wsl --cd ~/projects/mcp-servers/quickstart-resources/weather-server-python -- /home/samfire5200/.local/bin/uv run weather.py
```

### MCP Servers architecture

- The Model Context Protocol (**MCP**) is explicitly designed to facilitate smooth connections between **LLM applications** and **external data sources** and **tools**, as stated in the documentation. This seamless integration allows LLMs to effectively interact with various resources, enhancing their capabilities and utility.
- An **MCP Server** serves as a lightweight program that specifically **

---

### Model Context Protocol Architecture Overview

| MCP Client | â†” | MCP Server |
|------------|---|------------|
| - Invoke **Tools** |   | - Exposes **Tools** |
| - Queries for **Resources** |   | - Exposes **Resources** |
| - Interpolates **Prompts** |   | - Exposes **Prompts** |

| **Tools**                | **Resources**               | **Prompts**                    |
|--------------------------|-----------------------------|--------------------------------|
| *Model-Controlled*       | *Application-Controlled*    | *User-Controlled*              |
| Functions invoked by the model | Data exposed to the application | Pre-defined templates for AI interactions |
| - Retrieve / Search      | - Files                     | - Documentation Q&A            |
| - Send Message           | - DB Records                | - Transcript Summary           |
| - Update DB              | - API Responses             | - Output as JSON               |

---

## MCP æž¶æ§‹çš„å…©å€‹è§’è‰²èªªæ˜Ž

### **MCP Client**

* è² è²¬ï¼š

  * å‘¼å« **Tools**ï¼ˆå·¥å…·ï¼‰
  * æŸ¥è©¢ **Resources**ï¼ˆè³‡æºï¼‰
  * ä½¿ç”¨ **Prompts**ï¼ˆæç¤ºæ¨¡æ¿ï¼‰åŽ»å¡«å……äº’å‹•å…§å®¹

â†’ å®ƒç›¸ç•¶æ–¼**AI æ¨¡åž‹ç«¯**ï¼Œæˆ–æ˜¯ã€Œ**ä½¿ç”¨è€…çš„ä»£ç†äºº**ã€ã€‚

---

### **MCP Server**

* è² è²¬ï¼š

  * æä¾›ï¼ˆexposeï¼‰**Tools**
  * æä¾› **Resources**
  * æä¾› **Prompts**

â†’ å®ƒç›¸ç•¶æ–¼**å¾Œç«¯æœå‹™ç«¯**ï¼Œæˆ–æ˜¯ã€Œ**å·¥å…·ç®±**ã€**è³‡æ–™åº«**æˆ– **API** ä¾†æºã€ã€‚

---

## MCP æž¶æ§‹çš„ä¸‰å€‹æ ¸å¿ƒæ¦‚å¿µèªªæ˜Ž

### **Tools** *(æ¨¡åž‹æŽ§åˆ¶)*

* æ˜¯æ¨¡åž‹èƒ½ç›´æŽ¥å‘¼å«çš„å‡½å¼ï¼Œä¾‹å¦‚ï¼š

  * Retrieve/Search â†’ æœå°‹è³‡æ–™
  * Send Message â†’ å‚³é€è¨Šæ¯
  * Update DB â†’ æ›´æ–°è³‡æ–™åº«

---

### **Resources** *(æ‡‰ç”¨ç¨‹å¼æŽ§åˆ¶)*

* æ˜¯ MCP Server æä¾›çš„è³‡æ–™ï¼Œä¾‹å¦‚ï¼š

  * Files â†’ æª”æ¡ˆ
  * DB Records â†’ è³‡æ–™åº«ç´€éŒ„
  * API Responses â†’ API å›žå‚³çµæžœ

---

### **Prompts** *(ä½¿ç”¨è€…æŽ§åˆ¶)*

* æ˜¯å·²å®šç¾©å¥½çš„æç¤ºæ¨¡æ¿ï¼Œä¾‹å¦‚ï¼š

  * Documentation Q\&A â†’ æ–‡ä»¶å•ç­”
  * Transcript Summary â†’ æ‘˜è¦é€å­—ç¨¿
  * Output as JSON â†’ ä»¥ JSON æ ¼å¼è¼¸å‡º

---

### âœ… å¯¦ä¾‹èªªæ˜Ž

**ä¾‹å­ 1 â€” æ’°å¯«æŠ€è¡“æ–‡ä»¶å•ç­”æ©Ÿå™¨äºº**

* **å ´æ™¯**ï¼š

  * ä½¿ç”¨è€…æƒ³å»ºç«‹ä¸€å€‹ AI åŠ©ç†ï¼Œå¯ä»¥å›žç­”å…¬å¸æŠ€è¡“æ–‡ä»¶çš„å•é¡Œã€‚

* **MCP Server**ï¼š

  * æš´éœ²ï¼š

    * **Tools** â†’ æœå°‹æŠ€è¡“æ–‡ä»¶
    * **Resources** â†’ æŠ€è¡“æ–‡ä»¶æª”æ¡ˆ
    * **Prompts** â†’ Documentation Q\&A æ¨¡æ¿

* **MCP Client**ï¼š

  * æ¨¡åž‹æ”¶åˆ°å•é¡Œï¼š

    > ã€Œè«‹å•ç”¢å“ X æ”¯æ´å“ªäº›ä½œæ¥­ç³»çµ±ï¼Ÿã€
  * å‘¼å« Tool â†’ `Retrieve/Search` æŠ€è¡“æ–‡ä»¶
  * æŸ¥åˆ°å…§å®¹ â†’ å¾ž Resource `Files` ä¸­æ’ˆè³‡æ–™
  * ç”¨ Prompt `Documentation Q&A` æ ¼å¼ï¼Œç”Ÿæˆå›žç­”ï¼š

    > ã€Œç”¢å“ X æ”¯æ´ Windowsã€Linuxã€macOS ç³»çµ±ã€‚ã€

---

**ä¾‹å­ 2 â€” å®¢æœèŠå¤©æ©Ÿå™¨äºº**

* **å ´æ™¯**ï¼š

  * ä½¿ç”¨è€…æƒ³å»ºç«‹å®¢æœæ©Ÿå™¨äººï¼Œèƒ½å›žè¦†å®¢æˆ¶è¨Šæ¯ï¼Œä¸¦æ›´æ–°å®¢æˆ¶è³‡æ–™ã€‚

* **MCP Server**ï¼š

  * æš´éœ²ï¼š

    * **Tools** â†’ Send Messageã€Update DB
    * **Resources** â†’ å®¢æˆ¶ç´€éŒ„ (DB Records)
    * **Prompts** â†’ Transcript Summary (è‡ªå‹•ç”Ÿæˆå°è©±ç´€éŒ„æ‘˜è¦)

* **MCP Client**ï¼š

  * æ¨¡åž‹ï¼š

    * æ”¶åˆ°å®¢æˆ¶è¨Šæ¯ â†’ å‘¼å« `Send Message`
    * å®¢æˆ¶è¦æ±‚æ›´æ–°è¯çµ¡è³‡è¨Š â†’ å‘¼å« `Update DB`
    * ç”¢å‡ºæ‘˜è¦ â†’ ä½¿ç”¨ `Transcript Summary` Prompt

çµæžœï¼š

> ã€Œå·²æ›´æ–°æ‚¨çš„é›»è©±è™Ÿç¢¼ã€‚ä»¥ä¸‹æ˜¯æœ¬æ¬¡å°è©±æ‘˜è¦ï¼šâ€¦ã€

---

**ç°¡å–®ä¸€å¥è©±**ï¼š

> é€™å¼µåœ–å°±æ˜¯åœ¨èªªï¼š**Client è² è²¬è«‹æ±‚ï¼ŒServer è² è²¬æä¾›å·¥å…·ã€è³‡æ–™å’Œæç¤ºï¼Œè®“ AI æ¨¡åž‹èƒ½å®Œæˆå„ç¨®ä»»å‹™ã€‚**

---

## MCP Inspector

- https://modelcontextprotocol.io/docs/tools/inspector

> **MCP Inspector** æ˜¯ä¸€å€‹åœ–å½¢åŒ–çš„é™¤éŒ¯èˆ‡æ¸¬è©¦å·¥å…·ï¼Œå¹«åŠ©é–‹ç™¼è€…æŽ¢ç´¢å’Œé©—è­‰ MCP Server çš„ Toolsã€Resources å’Œ Promptsï¼Œç¢ºä¿å®ƒå€‘åœ¨é€£æŽ¥åˆ°å®¢æˆ¶ç«¯æˆ– LLM ä¹‹å‰æ­£å¸¸é‹ä½œã€‚

### âœ… MCP Inspector ä½¿ç”¨æ–¹å¼

```
cd quickstart-resources\weather-server-typescript
node build\index.js
```

```
cd quickstart-resources\weather-server-typescript
npx @modelcontextprotocol/inspector

```

```
Starting MCP inspector...
âš™ï¸ Proxy server listening on 127.0.0.1:6277
ðŸ”‘ Session token: a70e7d7d79cea9f735ee7237f0e5b3df9c867b8eea1e431cb9783e746263908e
Use this token to authenticate requests or set DANGEROUSLY_OMIT_AUTH=true to disable auth

ðŸ”— Open inspector with token pre-filled:
   http://localhost:6274/?MCP_PROXY_AUTH_TOKEN=a70e7d7d79cea9f735ee7237f0e5b3df9c867b8eea1e431cb9783e746263908e

ðŸ” MCP Inspector is up and running at http://127.0.0.1:6274 ðŸš€

```

- http://localhost:6274/?MCP_PROXY_AUTH_TOKEN=a70e7d7d79cea9f735ee7237f0e5b3df9c867b8eea1e431cb9783e746263908e#resources

- **Transport Type** (STDIO)
- **Command** (node)
- **Arguments** (build/index.js)
=> Connect

---

## McpDoc

- https://langchain-ai.github.io/langgraph/llms-txt-overview/
- https://github.com/langchain-ai/mcpdoc

éžå¸¸æ£’ï¼ä½ çš„ç†è§£ **å¹¾ä¹Žå®Œå…¨æ­£ç¢º**ï¼Œä½†å¯ä»¥å†æ›´ç²¾ç¢ºä¸€é»žã€‚ä»¥ä¸‹ç”¨ä¸­æ–‡è©³ç´°èªªæ˜Žï¼š

---

### âœ… MCPDoc æ˜¯ä»€éº¼ï¼Ÿ

âœ… MCPDoc æ˜¯ä¸€å€‹ **MCP Server**ï¼Œå°ˆé–€ç”¨ä¾†å³æ™‚ç²å–æœ€æ–°çš„ **LLM ç›¸é—œå®˜æ–¹æ–‡ä»¶æˆ–æŠ€è¡“èªªæ˜Ž**ã€‚

> MCPDoc å°±æ˜¯ç”¨ä¾†ã€ŒæŠ“å®˜æ–¹æ–‡ä»¶ã€çš„ MCP Serverï¼Œå¹«åŠ© AI å·¥å…·å³æ™‚è®€åˆ°æœ€æ–° LLM æŠ€è¡“æ–‡ä»¶èˆ‡èªªæ˜Žï¼Œè€Œä¸æ˜¯æŠ“æ¨¡åž‹å…§éƒ¨åƒæ•¸ã€‚
> MCPDoc å¹« AI å·¥å…·æŠŠå®˜æ–¹æ–‡ä»¶è®Šæˆå³æ™‚çŸ¥è­˜ï¼Œç¢ºä¿å›žç­”åŸºæ–¼æœ€æ–°è³‡æ–™ã€‚

---

### âœ… LLMs.txt æ˜¯ä»€éº¼ï¼Ÿ

LLMs.txt ä¸¦ **ä¸æ˜¯ç›´æŽ¥ç”¨ä¾†ç²å–æœ€æ–° LLM è¨Šæ¯**ã€‚

- å®ƒçš„çœŸæ­£ç”¨é€”æ˜¯ï¼š **å‘Šè¨´ MCP Serverï¼š**

   * å“ªäº› LLM è¦ç”¨ï¼ˆå¦‚ GPT-4ã€Claude 3ï¼‰
   * ä½¿ç”¨ä»€éº¼åƒæ•¸ï¼ˆä¾‹å¦‚æº«åº¦ã€top\_pï¼‰
   * å“ªäº›ç¶²å€åŒ…å«ç›¸é—œæ–‡ä»¶æˆ–è³‡æºï¼ˆä¾‹å¦‚å®˜æ–¹æ–‡ä»¶ï¼‰

---

### âœ… MCP Server å¦‚ä½•ç”¨åˆ° LLMs.txtï¼Ÿ

â†’ MCP Server **æ ¹æ“š LLMs.txt è£¡çš„ç¶²å€ (URL)**

* åŽ»æŠ“å–æœ€æ–°çš„æ–‡ä»¶å…§å®¹
* æŠŠæŠ“åˆ°çš„å…§å®¹ï¼Œæä¾›çµ¦åƒ Claudeã€Cursor ç­‰ AI å·¥å…·
* è®“ AI å›žç­”æ™‚ï¼Œæ ¹æ“šæœ€æ–°çš„å®˜æ–¹æ–‡ä»¶ï¼Œè€Œä¸æ˜¯èˆŠçš„æ¨¡åž‹çŸ¥è­˜

---

#### llms.txt é•·é€™æ¨£ï¼š

```
[openai]
model = "gpt-4"
temperature = 0.3
docs_url = "https://platform.openai.com/docs"

[langgraph]
docs_url = "https://langchain-ai.github.io/langgraph/llms.txt"
```

---

### âœ… ç¸½çµ

* âŒ LLMs.txt **ä¸æ˜¯**ç›´æŽ¥ä¿å­˜æœ€æ–°çš„ LLM è¨Šæ¯
* âœ… å®ƒæ˜¯ MCP Server çš„ã€Œå°Žèˆªåœ–ã€ï¼š

  * å‘Šè¨´ Server è¦åŽ»å“ªè£¡æŠ“æœ€æ–°è³‡æ–™
  * ç®¡ç† LLM è¨­å®šï¼ˆæ¨¡åž‹åã€åƒæ•¸ï¼‰
* MCP Server **æ‰æ˜¯çœŸæ­£è² è²¬åŽ»æŠ“æœ€æ–°æ–‡ä»¶çš„è§’è‰²**

---

### âœ… å®‰è£èˆ‡å•Ÿå‹• MCPDoc

```cmd
git colon https://github.com/langchain-ai/mcpdoc.git
cd mcpdoc

uvx --from mcpdoc mcpdoc --urls "LangGraph:https://langchain-ai.github.io/langgraph/llms.txt" "LangChain:https://python.langchain.com/llms.txt" --transport sse --port 8087 --host localhost
```

```note
  ...
  INFO:     Waiting for application startup.
  INFO:     Application startup complete.
  INFO:     Uvicorn running on http://localhost:8087 (Press CTRL+C to quit)    
```

### ä½¿ç”¨ MCP Inspector æª¢æŸ¥ MCPDoc

```cmd
cd mcpdoc
npx @modelcontextprotocol/inspector uvx --from mcpdoc mcpdoc --urls "LangGraph:https://langchain-ai.github.io/langgraph/llms.txt" "LangChain:https://python.langchain.com/llms.txt" --transport sse --port 8087 --host localhost
```

```note
Starting MCP inspector...
âš™ï¸ Proxy server listening on 127.0.0.1:6277
ðŸ”‘ Session token: 69f0505c3cb65501ab26bac0e445d6f381f4320d7dc0918544881b521d0cb531
Use this token to authenticate requests or set DANGEROUSLY_OMIT_AUTH=true to disable auth

ðŸ”— Open inspector with token pre-filled:
   http://localhost:6274/?MCP_PROXY_AUTH_TOKEN=69f0505c3cb65501ab26bac0e445d6f381f4320d7dc0918544881b521d0cb531

ðŸ” MCP Inspector is up and running at http://127.0.0.1:6274 ðŸš€
```

#### Inspector connect to MCPDoc
http://localhost:6274/?MCP_PROXY_AUTH_TOKEN=69f0505c3cb65501ab26bac0e445d6f381f4320d7dc0918544881b521d0cb531

- **Transport Type** (SSE)
- **URL** (http://localhost:8087/sse)
=> Connect -> Tools -> List Tools -> 
  - list_doc_sources => Run Tools 
  - fetch_docs => url (https://langchain-ai.github.io/langgraph/llms.txt) => Run Tools

#### Claude to work with MCPDoc

Edit claude_desktop_config.json

```
...
{
  "mcpServers": {
    ...,
    "langgraph-docs-mcp": {
    "command": "C:/Users/samfi/.local/bin/uvx",
    "args": [
      "--from",
      "D:/development/mcp-servers/mcpdoc",
      "mcpdoc",
      "--urls",
      "LangGraph:https://langchain-ai.github.io/langgraph/llms.txt LangChain:https://python.langchain.com/llms.txt",
      "--transport",
      "stdio"
      ]
    }
  }
}

```
What is LangGraph memory?
